{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import re \n",
    "from networkx.algorithms.community.quality import coverage, performance\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from networkx.algorithms.centrality import edge_betweenness_centrality as edge_bet\n",
    "from networkx.algorithms.shortest_paths.generic import average_shortest_path_length as len_short_path\n",
    "import numpy as np\n",
    "import pprint\n",
    "from typing import Dict\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import community\n",
    "# import nxmetis\n",
    "import time\n",
    "from math import ceil\n",
    "from sklearn import metrics\n",
    "pd.set_option('display.max_columns', 85)\n",
    "pd.set_option('display.max_rows', 85)\n",
    "import json\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import os\n",
    "import nltk\n",
    "from afinn import Afinn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import networkx as nx\n",
    "import re \n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#import igraph as ig\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import gensim\n",
    "from nltk.stem import PorterStemmer \n",
    "from networkx.algorithms.centrality import degree_centrality\n",
    "import random\n",
    "np.random.seed(2018)\n",
    "from gensim.models import CoherenceModel\n",
    "# https://towardsdatascience.com/graph-algorithms-part-2-dce0b2734a1d\n",
    "# https://github.com/taynaud/python-louvain/blob/master/community/community_louvain.py\n",
    "# https://networkx.github.io/documentation/stable/_modules/networkx/algorithms/community/quality.html\n",
    "# https://stackoverflow.com/questions/929103/convert-a-number-range-to-another-range-maintaining-ratio\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per aggiungere eventualmente altri dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./data/corona_virus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = nx.read_gml('Graph/Final_MultiGraph_Covid.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(multi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.read_gml('Graph/Final_Graph_Covid.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG = nx.read_gml('Graph/Final_DiGraph_Covid.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(CG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('./Dataset_marzo_JSON/slot3.csv')\n",
    "new_data.dropna(axis='index', how='all', subset=['text'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2114411, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b73c8964e34499997d7b49be88696d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "language = list()\n",
    "cont = 0\n",
    "for _, row in tqdm(new_data.iterrows()):\n",
    "    try:\n",
    "        language.append(detect(row['text']))\n",
    "    except:\n",
    "        language.append('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['lang'] = language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_eng_march = new_data.query(\"lang == 'en'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1178531, 14)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_eng_march.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_eng_march = final_eng_march.rename(columns={\"lang\": \"language\", \"text\": \"text_con_hashtag\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mentions(x):\n",
    "    p = re.compile(r'@\\s([^\\s:]+)')\n",
    "    return  ', '.join(p.findall(x))\n",
    "\n",
    "def remove_mentions(x):\n",
    "    p = re.sub(r'@\\s([^\\s:]+)', '', x)\n",
    "    return p\n",
    "\n",
    "final_eng_march[\"@mentions\"] = final_eng_march[\"text_con_hashtag\"].apply(find_mentions)\n",
    "final_eng_march[\"text_con_hashtag\"] = final_eng_march[\"text_con_hashtag\"].apply(remove_mentions)\n",
    "final_eng_march[\"@mentions\"] = final_eng_march[\"@mentions\"].str.lower()\n",
    "final_eng_march[\"username\"] = final_eng_march[\"username\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_eng_march = final_eng_march.drop_duplicates(subset=['text_con_hashtag', '@mentions', 'username', 'retweets', 'favorites'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_eng_march = final_eng_march[['username', 'favorites', 'retweets', \n",
    "        'language', '@mentions', 'geo', 'text_con_hashtag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>language</th>\n",
       "      <th>@mentions</th>\n",
       "      <th>geo</th>\n",
       "      <th>text_con_hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hccons_</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>Republic of Texas</td>\n",
       "      <td>It’s Coronavirus day 1,387. All the government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sarahplz</td>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>sc: sarahplz10</td>\n",
       "      <td>If you ever lived in woodcrest you are immune ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>thomnolan</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>Roscommon</td>\n",
       "      <td>As far as I can tell not one corona virus case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rexcorvinus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>Freedomland</td>\n",
       "      <td>Even w/o the coronavirus, \"longest bull market...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bondjam78417173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>Trump's Top Coronavirus Doctor Says It's Much ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           username  favorites  retweets language @mentions  \\\n",
       "5           hccons_          4         2       en             \n",
       "6          sarahplz         71        11       en             \n",
       "8         thomnolan          1         0       en             \n",
       "11      rexcorvinus          0         0       en             \n",
       "12  bondjam78417173          0         0       en             \n",
       "\n",
       "                  geo                                   text_con_hashtag  \n",
       "5   Republic of Texas  It’s Coronavirus day 1,387. All the government...  \n",
       "6      sc: sarahplz10  If you ever lived in woodcrest you are immune ...  \n",
       "8           Roscommon  As far as I can tell not one corona virus case...  \n",
       "11        Freedomland  Even w/o the coronavirus, \"longest bull market...  \n",
       "12              false  Trump's Top Coronavirus Doctor Says It's Much ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_eng_march.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_eng_march.to_csv('./last_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
